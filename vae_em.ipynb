{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Neafiol/Tinkoff/blob/master/vae_em.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "rfitdccJiGLB"
      },
      "cell_type": "markdown",
      "source": [
        "# Вариационный автоэнкодер\n",
        "\n",
        "Мотивация: нам никто вообще не гарантирует, что автоэнкодер работает, и что у него какое-то адекватное латентное пространство."
      ]
    },
    {
      "metadata": {
        "id": "UP5Ay1BEiGLR"
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "import tqdm\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aaNEgDIdiGLb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10b03a73-7639-4fa5-b624-6f7b749b3d8a"
      },
      "cell_type": "code",
      "source": [
        "dataset = datasets.MNIST('mnist', train=True, download=True, transform=transforms.ToTensor())\n",
        "loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 45.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist/MNIST/raw/train-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 2.02MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist/MNIST/raw/train-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 13.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 8.00MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to mnist/MNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "qjwlHo-siGLn"
      },
      "cell_type": "code",
      "source": [
        "class VAE(nn.Module):\n",
        "    def __init__(self, image_channels=1, h_dim=256, z_dim=32):\n",
        "        super().__init__()\n",
        "\n",
        "        self.encoder = nn.Sequential(\n",
        "            # ...\n",
        "        )\n",
        "\n",
        "        self.h2mu = nn.Linear(h_dim, z_dim)\n",
        "        self.h2sigma = nn.Linear(h_dim, z_dim)\n",
        "        self.z2h = nn.Linear(z_dim, h_dim)\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            # ...\n",
        "            nn.Sigmoid(),\n",
        "        )\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        # если не понимаете, как это работает, спросите\n",
        "        std = logvar.mul(0.5).exp_()\n",
        "        eps = torch.randn(*mu.size())\n",
        "        z = mu + std * eps\n",
        "        return z\n",
        "\n",
        "    def bottleneck(self, h):\n",
        "        mu = self.h2mu(h)\n",
        "        logvar = self.h2sigma(h)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        return z, mu, logvar\n",
        "\n",
        "    def encode(self, x):\n",
        "        # это можно использовать для морфинга, например\n",
        "        return self.bottleneck(self.encoder(x))[0]\n",
        "\n",
        "    def decode(self, z):\n",
        "        return self.decoder(self.z2h(z))\n",
        "\n",
        "    def forward(self, x):\n",
        "        h = self.encoder(x)\n",
        "        z, mu, logvar = self.bottleneck(h)\n",
        "        z = self.z2h(z)\n",
        "        return self.decoder(z), mu, logvar"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "oR7o1FBNiGLu"
      },
      "cell_type": "code",
      "source": [
        "def vae_loss(recon_x, x, mu, logvar):\n",
        "    BCE = F.binary_cross_entropy(recon_x.view(-1, 784), x.view(-1, 784), reduction='sum')\n",
        "    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
        "    return BCE + KLD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4RSvnbGaiGL0"
      },
      "cell_type": "code",
      "source": [
        "model = VAE()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ObP-T9diGL6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "outputId": "66ec6f3b-0d1a-402c-bd53-6fb0cb3ea68d"
      },
      "cell_type": "code",
      "source": [
        "for epoch in range(10):\n",
        "    train_loss = 0\n",
        "    for data, _ in tqdm.tqdm(loader):\n",
        "        # если вам лень писать свёртки:\n",
        "        # data = data.view(-1, 784)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        recon_batch, mu, logvar = model(data)\n",
        "\n",
        "        loss = vae_loss(recon_batch, data, mu, logvar)\n",
        "        loss.backward()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    print('epoch %d, loss %.4f' % (epoch, train_loss / len(dataset)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 0/938 [00:00<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "mat1 and mat2 shapes cannot be multiplied (1792x28 and 256x32)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-533e9c352f62>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvae_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecon_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-1a14000cf8f2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0mh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mz\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz2h\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-1a14000cf8f2>\u001b[0m in \u001b[0;36mbottleneck\u001b[0;34m(self, h)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mbottleneck\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m         \u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2mu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0mlogvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mh2sigma\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreparameterize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1792x28 and 256x32)"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "RaTwzpHRiGMI"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from IPython.display import HTML, display"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "G9BysauPiGMS"
      },
      "cell_type": "code",
      "source": [
        "def get(x):\n",
        "    return dataset[x][0].view(1, 784)  # измените формат, если хотите использовать свёртки\n",
        "\n",
        "def imshow(img):\n",
        "    pic = img.numpy().astype('float')\n",
        "    plt.axis('off')\n",
        "    return plt.imshow(pic, cmap='Greys', animated=True)\n",
        "\n",
        "def morph(inputs, steps, delay):\n",
        "    latent = [model.encode(get(k)).data for k in inputs]\n",
        "    fig = plt.figure()\n",
        "    images = []\n",
        "    for a, b in zip(latent, latent[1:] + [latent[0]]):\n",
        "        for t in np.linspace(0, 1, steps):\n",
        "            c = a*(1-t)+b*t\n",
        "            morphed = model.decode(c).data\n",
        "            morphed = morphed.view(28, 28)\n",
        "            images.append([imshow(morphed)])\n",
        "\n",
        "    ani = animation.ArtistAnimation(fig, images, interval=delay)\n",
        "\n",
        "    display(HTML(ani.to_html5_video()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "HuEKNP_NiGMi"
      },
      "cell_type": "code",
      "source": [
        "morph(np.random.randint(0, len(dataset), 30), 20, 30)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XLVxlAJLiGMt"
      },
      "cell_type": "markdown",
      "source": [
        "Дополнительное чтение для ноулайферов: [Tutorial on Variational Autoencoders](https://arxiv.org/pdf/1606.05908.pdf)."
      ]
    },
    {
      "metadata": {
        "id": "yQYsKwbFiGMv"
      },
      "cell_type": "markdown",
      "source": [
        "# EM-алгоритм"
      ]
    },
    {
      "metadata": {
        "id": "rTDM2CnliGMx"
      },
      "cell_type": "markdown",
      "source": [
        "Это задание было украдено с Deep Bayes 2018, а там оно в свою очередь было украдено у Чешского технического универсистета.\n",
        "\n",
        "Данные скачать можно тут: https://goo.gl/6eD3BB\n",
        "\n",
        "Немного помучайтесь с математикой, а когда надоест, посмотрите выводы формул здесь: https://github.com/bayesgroup/deepbayes-2018/blob/master/day1_em/seminar_em.pdf"
      ]
    },
    {
      "metadata": {
        "id": "M2cfmAG_iGMy"
      },
      "cell_type": "markdown",
      "source": [
        "Легенда такая: есть $K$ изображений, на которых изображен один из организаторов DeepBayes, но все из них были повреждены следующим процессом: есть фиксированное черно-белое изображение-фон $B$ (размера $W \\times H$), в каждом изоражении лицо $F$ (размера $w \\times H$) помещается в случайное место на фоне (для каждого изображения выбирается горизонтальный сдвиг $d_k$; априорные вероятности каждого сдвига обучаемы). Помимо этого, ко всем изображениям подмешивается белый шум (независимо ко всем пикселям) со средним 0 и дисперсией $s^2$.\n",
        "\n",
        "Ваша задача — восстановить лицо. Формально, нужно найти такую матрицу, что правдоподобие сгенерированных изображений максимально."
      ]
    },
    {
      "metadata": {
        "id": "obD7dAyiiGM0"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6Bs4AG3wiGM9"
      },
      "cell_type": "code",
      "source": [
        "w = 73  # ширина лица\n",
        "X = np.load(\"data_em\")  # путь до данных"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MN-T5TT9iGNE"
      },
      "cell_type": "code",
      "source": [
        "plt.imshow(X[:, :, 0], cmap=\"Greys_r\")\n",
        "plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j45w69vFiGNM"
      },
      "cell_type": "markdown",
      "source": [
        "Наша цель — найти лицо $F$ (матрица размера $H \\times w$).\n",
        "\n",
        "Также в процессе нам потребуется найти:\n",
        "* $B$: фон  ($H \\times W$)\n",
        "* $s^2$: дисперсию шума (скаляр)\n",
        "* $a$: априорные вероятности сдвигов ($W-w+1$ штук, должны суммироваться в единицу)\n",
        "* $q(d)$: постериорные вероятности сдвигов для каждого изображения  (($W-w+1$) x $K$)\n",
        "\n",
        "План реализации такой:\n",
        "1. Вычислить $\\log p(X  \\mid d,\\,F,\\,B,\\,s)$\n",
        "2. E-шаг: посчитать $q(d)$\n",
        "3. M-шаг: найти самые правдоподобные $F,\\, B, \\,s, \\,a$\n",
        "4. Соединить вместе E-шаг и M-шаг"
      ]
    },
    {
      "metadata": {
        "id": "GVNUy9VziGNN"
      },
      "cell_type": "code",
      "source": [
        "# EM-алгоритм может работать долго, и на больших данных его трудно тестировать\n",
        "tH, tW, tw, tK = 2, 3, 1, 2\n",
        "tX = np.arange(tH*tW*tK).reshape(tH, tW, tK)\n",
        "tF = np.arange(tH*tw).reshape(tH, tw)\n",
        "tB = np.arange(tH*tW).reshape(tH, tW)\n",
        "ts = 0.1\n",
        "ta = np.arange(1, (tW-tw+1)+1)\n",
        "ta = ta / ta.sum()\n",
        "tq = np.arange(1, (tW-tw+1)*tK+1).reshape(tW-tw+1, tK)\n",
        "tq = tq / tq.sum(axis=0)[np.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k68Rdi01iGNS"
      },
      "cell_type": "markdown",
      "source": [
        "## Вычисляем лог-вероятности\n",
        "\n",
        "Для $k$-го изображения $X_k$ и сдвига $d_k$, его правдоподобие будет равно:\n",
        "\n",
        "$$p(X_k  \\mid d_k,\\,F,\\,B,\\,s) = \\prod_{ij}\n",
        "    \\begin{cases}\n",
        "    \t\\mathcal{N}(X_k[i,j]\\mid F[i,\\,j-d_k],\\,s^2),\n",
        "    \t& \\text{if}\\, (i,j)\\in faceArea(d_k)\\\\\n",
        "    \t\\mathcal{N}(X_k[i,j]\\mid B[i,j],\\,s^2), & \\text{else}\n",
        "    \\end{cases}$$\n",
        "\n",
        "Примечание:\n",
        "* Не забудьте, что нам нужен логарифм всего этого.\n",
        "* Желательно использовать не более одного цикла."
      ]
    },
    {
      "metadata": {
        "id": "sbuCqq7qiGNV"
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.signal import fftconvolve\n",
        "import scipy.stats as st\n",
        "from scipy.special import logsumexp, softmax\n",
        "\n",
        "def calculate_log_probability(X, F, B, s):\n",
        "    \"\"\"\n",
        "    Calculates log p(X_k|d_k, F, B, s) for all images X_k in X and\n",
        "    all possible face position d_k.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape (H, W, K)\n",
        "        K images of size H x W.\n",
        "    F : array, shape (H, w)\n",
        "        Estimate of prankster's face.\n",
        "    B : array, shape (H, W)\n",
        "        Estimate of background.\n",
        "    s : float\n",
        "        Estimate of standard deviation of Gaussian noise.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    ll : array, shape(W-w+1, K)\n",
        "        ll[dw, k] - log-likelihood of observing image X_k given\n",
        "        that the prankster's face F is located at position dw\n",
        "    \"\"\"\n",
        "    H, W, _ = X.shape\n",
        "    h, w = F.shape\n",
        "\n",
        "    sq_diff = fftconvolve(X, np.flip(F.reshape(h, w, 1), axis=(0, 1)), mode='valid')\n",
        "    backgr_conv = X * np.expand_dims(B, axis=-1)\n",
        "    sq_diff -= fftconvolve(backgr_conv, np.ones((h, w, 1)), mode='valid')\n",
        "\n",
        "    sq_diff += np.sum(backgr_conv, axis=(0, 1), keepdims=True)\n",
        "    sq_diff *= -2\n",
        "    sq_diff += np.sum(X ** 2, axis=(0, 1)).reshape(1, 1, -1)\n",
        "    sq_diff += np.sum(F ** 2)\n",
        "    sq_diff += np.sum(B ** 2, axis=(0, 1))\n",
        "    sq_diff -= fftconvolve((B ** 2).reshape(H, W, 1), np.ones((h, w, 1)), mode='valid')\n",
        "\n",
        "    ll = -1 / (2 * s ** 2) * sq_diff - H * W * (np.log(s * np.sqrt(2 * np.pi)))\n",
        "    return ll"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q7pDpIF9iGNi"
      },
      "cell_type": "code",
      "source": [
        "# run this cell to test your implementation\n",
        "expected = np.array([[-3541.69812064, -5541.69812064],\n",
        "       [-4541.69812064, -6741.69812064],\n",
        "       [-6141.69812064, -8541.69812064]])\n",
        "actual = calculate_log_probability(tX, tF, tB, ts)\n",
        "assert np.allclose(actual, expected)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "gn0KP8MNiGNo"
      },
      "cell_type": "markdown",
      "source": [
        "## `сalculate_lower_bound`\n",
        "\n",
        "$$\\mathcal{L}(q, \\,F, \\,B,\\, s,\\, a) = \\sum_k \\biggl (\\mathbb{E} _ {q( d_k)}\\bigl ( \\log p(  X_{k}  \\mid {d}_{k} , \\,F,\\,B,\\,s) +\n",
        "    \\log p( d_k  \\mid a)\\bigr) - \\mathbb{E} _ {q( d_k)} \\log q( d_k)\\biggr) $$\n",
        "    \n",
        "Примечания:\n",
        "* Вы уже реализовали `calculate_log_probability` — используйте её.\n",
        "* Распределения $q(d_k)$ и $p( d_k  \\mid a)$ дискретные. For example, $P(d_k=i \\mid a) = a[i]$.\n",
        "* Старайтесь не использовать циклы."
      ]
    },
    {
      "metadata": {
        "id": "_p3xtDB8iGNr"
      },
      "cell_type": "code",
      "source": [
        "def calculate_lower_bound(X, F, B, s, A, q, use_MAP=False):\n",
        "    \"\"\"\n",
        "    Calculates the lower bound L(q, F, B, s, a) for\n",
        "    the marginal log likelihood.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape (H, W, K)\n",
        "        K images of size H x W.\n",
        "    F : array, shape (H, w)\n",
        "        Estimate of prankster's face.\n",
        "    B : array, shape (H, W)\n",
        "        Estimate of background.\n",
        "    s : float\n",
        "        Estimate of standard deviation of Gaussian noise.\n",
        "    a : array, shape (W-w+1)\n",
        "        Estimate of prior on position of face in any image.\n",
        "    q : array\n",
        "        q[dw, k] - estimate of posterior\n",
        "                   of position dw\n",
        "                   of prankster's face given image Xk\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    L : float\n",
        "        The lower bound L(q, F, B, s, a)\n",
        "        for the marginal log likelihood.\n",
        "    \"\"\"\n",
        "    H, W, K = X.shape\n",
        "    h, w = F.shape\n",
        "    log_prob = calculate_log_probability(X, F, B, s)\n",
        "    log_A = np.log(A + 1e-12)\n",
        "    if not use_MAP:\n",
        "        L = np.sum((log_prob + log_A.reshape(H - h + 1, W - w + 1, 1) - np.log(q + 1e-12)) * q)\n",
        "        return L\n",
        "\n",
        "    i_indices = q[0, :].astype(int)\n",
        "    j_indices = q[1, :].astype(int)\n",
        "    L = np.sum(log_prob[i_indices, j_indices, np.arange(K)] + log_A[i_indices, j_indices])\n",
        "    return L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "S8Q-xcLLiGNx"
      },
      "cell_type": "code",
      "source": [
        "expected = -12761.1875\n",
        "actual = calculate_lower_bound(tX, tF, tB, ts, ta, tq)\n",
        "assert np.allclose(actual, expected)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "xT0MMu1GiGN-"
      },
      "cell_type": "markdown",
      "source": [
        "## E-step\n",
        "\n",
        "$$q(d_k) = p(d_k \\mid X_k, \\,F, \\,B, \\,s,\\, a) =\n",
        "\\frac {p(  X_{k}  \\mid {d}_{k} , \\,F,\\,B,\\,s)\\, p(d_k \\mid a)}\n",
        "{\\sum_{d'_k} p(  X_{k}  \\mid d'_k , \\,F,\\,B,\\,s) \\,p(d'_k \\mid a)}$$\n",
        "\n",
        "Примечания:\n",
        "* Используйте `calculate_log_probability`.\n",
        "* Ради вычислительной стабильности, используйте операции с логарифмированными значениями и только в конце возводите в экспоненту. Также используйте этот трюк с софтмаксом:\n",
        "$$\\beta_i = \\log{p_i(\\dots)} \\quad\\rightarrow \\quad\n",
        "\t\\frac{e^{\\beta_i}}{\\sum_k e^{\\beta_k}} =\n",
        "\t\\frac{e^{(\\beta_i - \\max_j \\beta_j)}}{\\sum_k e^{(\\beta_k- \\max_j \\beta_j)}}$$\n",
        "* Старайтесь не использовать циклы"
      ]
    },
    {
      "metadata": {
        "id": "lHgUm_C6iGOC"
      },
      "cell_type": "code",
      "source": [
        "def run_e_step(X, F, B, s, a):\n",
        "    \"\"\"\n",
        "    Given the current esitmate of the parameters, for each image Xk\n",
        "    esitmates the probability p(d_k|X_k, F, B, s, a).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape(H, W, K)\n",
        "        K images of size H x W.\n",
        "    F  : array_like, shape(H, w)\n",
        "        Estimate of prankster's face.\n",
        "    B : array shape(H, W)\n",
        "        Estimate of background.\n",
        "    s : float\n",
        "        Eestimate of standard deviation of Gaussian noise.\n",
        "    a : array, shape(W-w+1)\n",
        "        Estimate of prior on face position in any image.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    q : array\n",
        "        shape (W-w+1, K)\n",
        "        q[dw, k] - estimate of posterior of position dw\n",
        "        of prankster's face given image Xk\n",
        "    \"\"\"\n",
        "    # your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vSPtccPViGOI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 332
        },
        "outputId": "0b95de07-e655-41ce-e50d-1e3ae63c954e"
      },
      "cell_type": "code",
      "source": [
        "expected = np.array([[ 1.,  1.],\n",
        "                   [ 0.,  0.],\n",
        "                   [ 0.,  0.]])\n",
        "actual = run_e_step(tX, tF, tB, ts, ta)\n",
        "assert np.allclose(actual, expected)\n",
        "print(\"OK\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-38f7216b1286>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                    \u001b[0;34m[\u001b[0m \u001b[0;36m0.\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;36m0.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                    [ 0.,  0.]])\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mactual\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_e_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32massert\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mactual\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"OK\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-9a9391fd71e5>\u001b[0m in \u001b[0;36mrun_e_step\u001b[0;34m(X, F, B, s, A, use_MAP)\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_log_probability\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m     \u001b[0mlog_prob_A\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlog_prob\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1e-12\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m     \u001b[0mlog_prob_A\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlogsumexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob_A\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "-H47Ki2CiGOQ"
      },
      "cell_type": "markdown",
      "source": [
        "## M-step\n",
        "\n",
        "$$a[j] = \\frac{\\sum_k q( d_k = j )}{\\sum_{j'}  \\sum_{k'} q( d_{k'} = j')}$$\n",
        "$$F[i, m] = \\frac 1 K  \\sum_k \\sum_{d_k} q(d_k)\\, X^k[i,\\, m+d_k]$$\n",
        "$$B[i, j] = \\frac {\\sum_k \\sum_{ d_k:\\, (i, \\,j) \\,\\not\\in faceArea(d_k)} q(d_k)\\, X^k[i, j]}\n",
        "\t  \t{\\sum_k \\sum_{d_k: \\,(i, \\,j)\\, \\not\\in faceArea(d_k)} q(d_k)}$$\n",
        "$$s^2 = \\frac 1 {HWK}   \\sum_k \\sum_{d_k} q(d_k)\n",
        "\t  \t\\sum_{i,\\, j}  (X^k[i, \\,j] - M^{d_k}[i, \\,j])^2$$\n",
        "\n",
        "где $M^{d_k}[i, j]$ это изображение из фона, с наложенным на него лицом со сдвигом $d_k$.\n",
        "\n",
        "Примечания:\n",
        "* Порядок обновления параметров: $a$, $F$, $B$, $s$.\n",
        "* Когда параметр обновляется, его __новое__ значение используется для обновления других параметров.\n",
        "* Используйте не более 3 циклов (отдельных, не вложенных)."
      ]
    },
    {
      "metadata": {
        "id": "_XjcpH_NiGOT"
      },
      "cell_type": "code",
      "source": [
        "def run_m_step(X, q, w):\n",
        "    \"\"\"\n",
        "    Estimates F, B, s, a given esitmate of posteriors defined by q.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape (H, W, K)\n",
        "        K images of size H x W.\n",
        "    q  :\n",
        "        q[dw, k] - estimate of posterior of position dw\n",
        "                   of prankster's face given image Xk\n",
        "    w : int\n",
        "        Face mask width.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    F : array, shape (H, w)\n",
        "        Estimate of prankster's face.\n",
        "    B : array, shape (H, W)\n",
        "        Estimate of background.\n",
        "    s : float\n",
        "        Estimate of standard deviation of Gaussian noise.\n",
        "    a : array, shape (W-w+1)\n",
        "        Estimate of prior on position of face in any image.\n",
        "    \"\"\"\n",
        "    # your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hBOphEhoiGOX"
      },
      "cell_type": "code",
      "source": [
        "expected = [\n",
        "    np.array([[ 3.27777778],\n",
        "              [ 9.27777778]]),\n",
        "    np.array([[  0.48387097, 2.5       ,   4.52941176],\n",
        "              [  6.48387097, 8.5       ,  10.52941176]]),\n",
        "    0.94868,\n",
        "    np.array([ 0.13888889,  0.33333333,  0.52777778])\n",
        "]\n",
        "actual = run_m_step(tX, tq, tw)\n",
        "for a, e in zip(actual, expected):\n",
        "    assert np.allclose(a, e)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4n20_gGziGOi"
      },
      "cell_type": "markdown",
      "source": [
        "## Соединяем всё вместе\n",
        "\n",
        "Инициализируйте чем-нибудь параметры, и повторяйте E- и M-шаги до сходимости. $\\mathcal{L}(q, \\,F, \\,B, \\,s, \\,a)$ должна строго увеличиваться после каждой итерации."
      ]
    },
    {
      "metadata": {
        "id": "alCl9O6uiGOo"
      },
      "cell_type": "code",
      "source": [
        "def run_EM(X, w, F=None, B=None, s=None, a=None, tolerance=0.001, max_iter=50):\n",
        "    \"\"\"\n",
        "    Runs EM loop until the likelihood of observing X given current\n",
        "    estimate of parameters is idempotent as defined by a fixed\n",
        "    tolerance.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    X : array, shape (H, W, K)\n",
        "        K images of size H x W.\n",
        "    w : int\n",
        "        Face mask width.\n",
        "    F : array, shape (H, w), optional\n",
        "        Initial estimate of prankster's face.\n",
        "    B : array, shape (H, W), optional\n",
        "        Initial estimate of background.\n",
        "    s : float, optional\n",
        "        Initial estimate of standard deviation of Gaussian noise.\n",
        "    a : array, shape (W-w+1), optional\n",
        "        Initial estimate of prior on position of face in any image.\n",
        "    tolerance : float, optional\n",
        "        Parameter for stopping criterion.\n",
        "    max_iter  : int, optional\n",
        "        Maximum number of iterations.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    F, B, s, a : trained parameters.\n",
        "    LL : array, shape(number_of_iters + 2,)\n",
        "        L(q, F, B, s, a) at initial guess,\n",
        "        after each EM iteration and after\n",
        "        final estimate of posteriors;\n",
        "        number_of_iters is actual number of iterations that was done.\n",
        "    \"\"\"\n",
        "    H, W, N = X.shape\n",
        "    if F is None:\n",
        "        F = np.random.randint(0, 255, (H, w))\n",
        "    if B is None:\n",
        "        B = np.random.randint(0, 255, (H, W))\n",
        "    if a is None:\n",
        "        a = np.ones(W - w + 1)\n",
        "        a /= np.sum(a)\n",
        "    if s is None:\n",
        "        s = np.random.rand()*pow(64,2)\n",
        "    # your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cka1nh3XiGOt"
      },
      "cell_type": "code",
      "source": [
        "res = run_EM(tX, tw, max_iter=3)\n",
        "LL = res[-1]\n",
        "assert np.alltrue(LL[1:] - LL[:-1] > 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PpTlfVN9iGOz"
      },
      "cell_type": "markdown",
      "source": [
        "## Так кто же на фотке?"
      ]
    },
    {
      "metadata": {
        "id": "UIVUDdIwiGO0"
      },
      "cell_type": "code",
      "source": [
        "def show(F, i=1, n=1):\n",
        "    plt.subplot(1, n, i)\n",
        "    plt.imshow(F, cmap=\"Greys_r\")\n",
        "    plt.axis(\"off\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bph9YJxuiGO6"
      },
      "cell_type": "code",
      "source": [
        "F, B, s, a = [None] * 4\n",
        "LL = []\n",
        "lens = [50, 100, 300, 500, 1000]\n",
        "iters = [5, 1, 1, 1, 1]\n",
        "plt.figure(figsize=(20, 5))\n",
        "for i, (l, it) in enumerate(zip(lens, iters)):\n",
        "    F, B, s, a, _ = run_EM(X[:, :, :l], w, F, B, s, a, max_iter=it)\n",
        "    show(F, i+1, 5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}